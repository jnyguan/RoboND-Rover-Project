{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in ground truth map and create 3-channel green version for overplotting\n",
    "# NOTE: images are read in by default with the origin (0, 0) in the upper left\n",
    "# and y-axis increasing downward.\n",
    "ground_truth = mpimg.imread('../calibration_images/map_bw.png')\n",
    "# This next line creates arrays of zeros in the red and blue channels\n",
    "# and puts the map into the green channel.  This is why the underlying \n",
    "# map output looks green in the display image\n",
    "ground_truth_3d = np.dstack((ground_truth*0, ground_truth*255, ground_truth*0)).astype(np.float)\n",
    "\n",
    "\n",
    "# Define RoverState() class to retain rover state parameters\n",
    "class RoverState():\n",
    "    def __init__(self):\n",
    "        self.start_time = None # To record the start time of navigation\n",
    "        self.total_time = None # To record total duration of navigation\n",
    "        self.img = None # Current camera image\n",
    "        self.pos = (50, 50) # Current position (x, y)\n",
    "        self.yaw = 30 # Current yaw angle\n",
    "        self.pitch = None # Current pitch angle\n",
    "        self.roll = None # Current roll angle\n",
    "        self.vel = None # Current velocity\n",
    "        self.steer = 0 # Current steering angle\n",
    "        self.throttle = 0 # Current throttle value\n",
    "        self.brake = 0 # Current brake value\n",
    "        self.nav_angles = None # Angles of navigable terrain pixels\n",
    "        self.nav_dists = None # Distances of navigable terrain pixels\n",
    "        self.ground_truth = ground_truth_3d # Ground truth worldmap\n",
    "        self.mode = 'forward' # Current mode (can be forward or stop)\n",
    "        self.throttle_set = 0.2 # Throttle setting when accelerating\n",
    "        self.brake_set = 10 # Brake setting when braking\n",
    "        # The stop_forward and go_forward fields below represent total count\n",
    "        # of navigable terrain pixels.  This is a very crude form of knowing\n",
    "        # when you can keep going and when you should stop.  Feel free to\n",
    "        # get creative in adding new fields or modifying these!\n",
    "        self.stop_forward = 50 # Threshold to initiate stopping\n",
    "        self.go_forward = 500 # Threshold to go forward again\n",
    "        self.max_vel = 2 # Maximum velocity (meters/second)\n",
    "        # Image output from perception step\n",
    "        # Update this image to display your intermediate analysis steps\n",
    "        # on screen in autonomous mode\n",
    "        self.vision_image = np.zeros((160, 320, 3), dtype=np.float) \n",
    "        # Worldmap\n",
    "        # Update this image with the positions of navigable terrain\n",
    "        # obstacles and rock samples\n",
    "        self.worldmap = np.zeros((200, 200, 3), dtype=np.float) \n",
    "        self.samples_pos = None # To store the actual sample positions\n",
    "        self.samples_found = 0 # To count the number of samples found\n",
    "        self.near_sample = 0 # Will be set to telemetry value data[\"near_sample\"]\n",
    "        self.picking_up = 0 # Will be set to telemetry value data[\"picking_up\"]\n",
    "        self.send_pickup = False # Set to True to trigger rock pickup\n",
    "# Initialize our rover \n",
    "Rover = RoverState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (160,320,3) into shape (160,320)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-41bed4e269cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m \u001b[0mtest_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperception_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRover\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-41bed4e269cc>\u001b[0m in \u001b[0;36mperception_step\u001b[0;34m(Rover)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m# 4 - update Rover.vision image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mRover\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolorsel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;31m# 5 - convert map image pixel values to rover centric coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (160,320,3) into shape (160,320)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "# Identify pixels above the threshold\n",
    "# Threshold of RGB > 160 does a nice job of identifying ground pixels only\n",
    "def color_thresh(img, rgb_thresh=(160, 160, 160)):\n",
    "\n",
    "    # Create an array of zeros same xy size as img\n",
    "    # obstacle, rock samples, and navigable terrain are on different channels\n",
    "#     color_select = np.zeros_like(img[:,:,0]) \n",
    "\n",
    "    color_select_obstacle = np.zeros_like(img[:,:,0])   \n",
    "    color_select_rock = np.zeros_like(img[:,:,0])\n",
    "    color_select_nav = np.zeros_like(img[:,:,0])\n",
    "\n",
    "    # Require that each pixel be above all three threshold values in RGB\n",
    "    # above_thresh will now contain a boolean array with \"True\"\n",
    "    # where threshold was met\n",
    "    above_thresh = (img[:,:,0] > rgb_thresh[0]) \\\n",
    "                & (img[:,:,1] > rgb_thresh[1]) \\\n",
    "                & (img[:,:,2] > rgb_thresh[2])           \n",
    "\n",
    "    # Index the array of zeros with the boolean array and set to 1\n",
    "    color_select_obstacle[above_thresh] = 1\n",
    "    color_select_rock[above_thresh] = 1\n",
    "    color_select_nav[above_thresh] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return color_select_obstacle, color_select_rock, color_select_nav\n",
    "\n",
    "# Define a function to convert to rover-centric coordinates\n",
    "def rover_coords(binary_img):\n",
    "    # Identify nonzero pixels\n",
    "    ypos, xpos = binary_img.nonzero()\n",
    "    # Calculate pixel positions with reference to the rover position being at the \n",
    "    # center bottom of the image.  \n",
    "    x_pixel = np.absolute(ypos - binary_img.shape[0]).astype(np.float)\n",
    "    y_pixel = -(xpos - binary_img.shape[0]).astype(np.float)\n",
    "    return x_pixel, y_pixel\n",
    "\n",
    "\n",
    "# Define a function to convert to radial coords in rover space\n",
    "def to_polar_coords(x_pixel, y_pixel):\n",
    "    # Convert (x_pixel, y_pixel) to (distance, angle) \n",
    "    # in polar coordinates in rover space\n",
    "    # Calculate distance to each pixel\n",
    "    dist = np.sqrt(x_pixel**2 + y_pixel**2)\n",
    "    # Calculate angle away from vertical for each pixel\n",
    "    angles = np.arctan2(y_pixel, x_pixel)\n",
    "    return dist, angles\n",
    "\n",
    "# Define a function to apply a rotation to pixel positions\n",
    "def rotate_pix(xpix, ypix, yaw):\n",
    "    # TODO:\n",
    "    # Convert yaw to radians\n",
    "    # Apply a rotation\n",
    "\n",
    "    # convert yaw angle from degrees to radians\n",
    "    yaw_rad = yaw * np.pi/180\n",
    "    \n",
    "    # perform rotation matrix\n",
    "    xpix_rotated = xpix * np.cos(yaw_rad) - ypix * np.sin(yaw_rad)\n",
    "    ypix_rotated = xpix * np.sin(yaw_rad) + ypix * np.cos(yaw_rad)\n",
    "\n",
    "    # Return the result  \n",
    "    return xpix_rotated, ypix_rotated\n",
    "\n",
    "# Define a function to perform a translation\n",
    "def translate_pix(xpix_rot, ypix_rot, xpos, ypos, scale): \n",
    "    # TODO:\n",
    "    # Apply a scaling and a translation\n",
    "\n",
    "    # perform translation and convert to integer since pixel values can't be float\n",
    "    xpix_translated = np.int_(xpos + xpix_rot / scale)\n",
    "    ypix_translated = np.int_(ypos + ypix_rot / scale)\n",
    "\n",
    "    # Return the result  \n",
    "    return xpix_translated, ypix_translated\n",
    "\n",
    "# Define a function to apply rotation and translation (and clipping)\n",
    "# Once you define the two functions above this function should work\n",
    "def pix_to_world(xpix, ypix, xpos, ypos, yaw, world_size, scale):\n",
    "    # Apply rotation\n",
    "    xpix_rot, ypix_rot = rotate_pix(xpix, ypix, yaw)\n",
    "    # Apply translation\n",
    "    xpix_tran, ypix_tran = translate_pix(xpix_rot, ypix_rot, xpos, ypos, scale)\n",
    "    # Perform rotation, translation and clipping all at once\n",
    "    x_pix_world = np.clip(np.int_(xpix_tran), 0, world_size - 1)\n",
    "    y_pix_world = np.clip(np.int_(ypix_tran), 0, world_size - 1)\n",
    "    # Return the result\n",
    "    return x_pix_world, y_pix_world\n",
    "\n",
    "# Define a function to perform a perspective transform\n",
    "def perspect_transform(img, src, dst):\n",
    "           \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    warped = cv2.warpPerspective(img, M, (img.shape[1], img.shape[0]))# keep same size as input image\n",
    "    \n",
    "    return warped\n",
    "\n",
    "\n",
    "# Apply the above functions in succession and update the Rover state accordingly\n",
    "def perception_step(Rover):\n",
    "    # Perform perception steps to update Rover()\n",
    "    # TODO: \n",
    "    # NOTE: camera image is coming to you in Rover.img\n",
    "    # 1) Define source and destination points for perspective transform\n",
    "    # 2) Apply perspective transform\n",
    "    # 3) Apply color threshold to identify navigable terrain/obstacles/rock samples\n",
    "    # 4) Update Rover.vision_image (this will be displayed on left side of screen)\n",
    "        # Example: Rover.vision_image[:,:,0] = obstacle color-thresholded binary image\n",
    "        #          Rover.vision_image[:,:,1] = rock_sample color-thresholded binary image\n",
    "        #          Rover.vision_image[:,:,2] = navigable terrain color-thresholded binary image\n",
    "\n",
    "    # 5) Convert map image pixel values to rover-centric coords\n",
    "    # 6) Convert rover-centric pixel values to world coordinates\n",
    "    # 7) Update Rover worldmap (to be displayed on right side of screen)\n",
    "        # Example: Rover.worldmap[obstacle_y_world, obstacle_x_world, 0] += 1\n",
    "        #          Rover.worldmap[rock_y_world, rock_x_world, 1] += 1\n",
    "        #          Rover.worldmap[navigable_y_world, navigable_x_world, 2] += 1\n",
    "\n",
    "    # 8) Convert rover-centric pixel positions to polar coordinates\n",
    "    # Update Rover pixel distances and angles\n",
    "        # Rover.nav_dists = rover_centric_pixel_distances\n",
    "        # Rover.nav_angles = rover_centric_angles\n",
    "\n",
    "#     samplefile = '../misc/sample.jpg'    \n",
    "    samplefile = \"../calibration_images/example_rock1.jpg\"\n",
    "    image = mpimg.imread(samplefile)\n",
    "    dst_size = 10\n",
    "    bottom_offset = 6\n",
    "\n",
    "    # 1 - define source and destination points\n",
    "    source = np.float32([[14, 140], [301 ,140],[200, 96], [118, 96]])\n",
    "    destination = np.float32([[image.shape[1]/2 - dst_size, image.shape[0] - bottom_offset],\n",
    "                  [image.shape[1]/2 + dst_size, image.shape[0] - bottom_offset],\n",
    "                  [image.shape[1]/2 + dst_size, image.shape[0] - 2*dst_size - bottom_offset], \n",
    "                  [image.shape[1]/2 - dst_size, image.shape[0] - 2*dst_size - bottom_offset],\n",
    "                  ]) \n",
    "\n",
    "    scale = 10\n",
    "\n",
    "    # 2 - apply perspective transform\n",
    "    warped = perspect_transform(image, source, destination)\n",
    "\n",
    "    # 3 - apply color threshold\n",
    "    colorsel_obs, colosel_rock, colorsel_nav = color_thresh(warped, rgb_thresh=(160, 160, 160))\n",
    "\n",
    "    # 4 - update Rover.vision image\n",
    "    Rover.vision_image[:,:,0] = colorsel_obs\n",
    "    Rover.vision_image[:,:,1] = colorsel_rock\n",
    "    Rover.vision_image[:,:,2] = colorsel_nav\n",
    "\n",
    "    # 5 - convert map image pixel values to rover centric coordinates\n",
    "    xpix, ypix = rover_coords(colorsel)\n",
    "\n",
    "    # 6 - convert rover centric pixel values to world coordinates\n",
    "    x_world, y_world = pix_to_world(\n",
    "        xpix, ypix, Rover.pos[0], Rover.pos[1],\n",
    "        Rover.yaw, Rover.worldmap.shape[0], scale)\n",
    "\n",
    "    # 7 - update rover worldmap to be displayed\n",
    "    Rover.worldmap[x_world, y_world, 0] += 1\n",
    "\n",
    "    # 8 - convert rover centric pixel positions to polar coordinates\n",
    "    Rover.nav_dists, Rover.nav_angles = to_polar_coords(xpix, ypix)\n",
    "    \n",
    " \n",
    "    \n",
    "    \n",
    "    return Rover.worldmap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_result = perception_step(Rover)\n",
    "\n",
    "plt.imshow(test_result)\n",
    "\n",
    "# print (len(test_result))\n",
    "# print (test_result[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 320)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(colorsel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
